{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6389f926-9cc0-4cdc-a380-66187a6f8e34",
   "metadata": {},
   "source": [
    "TT. News Collection for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388ca728-54ee-4562-9328-1fe9baad6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías.\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb742b40-9edb-4f67-93bc-9128beb9c904",
   "metadata": {},
   "source": [
    "URLs of RSS sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac2fa80-feb0-4868-91ea-a7327cdb958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de páginas relacionadas con noticias de criptomonedas.\n",
    "\n",
    "# HTTP - 200 OK.\n",
    "\"\"\" RSS Feeds (XML). \"\"\"\n",
    "urls_dict = {\n",
    "    #'coindesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/?outputType=xml',\n",
    "    'cointelegraph': 'https://cointelegraph.com/rss/tag/bitcoin',\n",
    "    'bitcoinmagazine': 'https://bitcoinmagazine.com/.rss/full/',\n",
    "    'cryptopotato': 'https://cryptopotato.com/feed/',\n",
    "    'cryptoslate': 'https://cryptoslate.com/feed/',\n",
    "    'cryptonews': 'https://cryptonews.com/news/feed/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d76b48-bcdd-4d43-8575-f97aed15c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo CSV para almacenar las noticias\n",
    "csv_file = 'news_data.csv'\n",
    "\n",
    "# Cargar datos previos si el archivo existe\n",
    "if os.path.exists(csv_file):\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "else:\n",
    "    existing_df = pd.DataFrame()  # Crear un DataFrame vacío si no existe el archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa7372-f2b5-48ab-891e-1a44d485157a",
   "metadata": {},
   "source": [
    "Getting soup and items for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e26d2f2-7f65-463d-baa5-4299ea073622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from cointelegraph:\n",
      "<Response [200]>\n",
      "Items from cointelegraph:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from bitcoinmagazine:\n",
      "<Response [200]>\n",
      "Items from bitcoinmagazine:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptopotato:\n",
      "<Response [200]>\n",
      "Items from cryptopotato:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptoslate:\n",
      "<Response [200]>\n",
      "Items from cryptoslate:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptonews:\n",
      "<Response [200]>\n",
      "Items from cryptonews:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una lista para almacenar características de las noticias.\n",
    "news_data = []\n",
    "\n",
    "# Hacer solicitudes HTTP a las páginas web.\n",
    "for name, url in urls_dict.items():\n",
    "    response = requests.get(url)\n",
    "    print(f'Response from {name}:')\n",
    "    print(response)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parsear el contenido de las respuestas con BeautifulSoup.\n",
    "        soup = BeautifulSoup(response.content, 'xml')\n",
    "\n",
    "        # Extraer todos los elementos <item>.\n",
    "        items = soup.find_all('item')\n",
    "        print(f'Items from {name}:')\n",
    "        \n",
    "        # ----------------------------------------------------------------------- CoinDesk News. ----------------------------------------------------------------------- #\n",
    "        \"\"\"\n",
    "        if name == 'coindesk':\n",
    "            # Iterar cada elemento <item> y extraer características de las noticias de CoinDesk\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo.\n",
    "                    article_response = requests.get(link)\n",
    "                    article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    article_paragraphs = article_soup.find_all('p')\n",
    "                    article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "                    \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'CoinDesk',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': article_content\n",
    "                    })\n",
    "            \"\"\"\n",
    "        # ----------------------------------------------------------------------- CoinTelegraph News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cointelegraph':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia. \n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                #description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "            \n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "            \n",
    "                # Filtrar solo las noticias de Bitcoin\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                    \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = article_soup.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'CoinTelegraph',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description\n",
    "                        #'content': article_content\n",
    "                    })\n",
    "\n",
    "        # ----------------------------------------------------------------------- BitcoinMagazine News. ----------------------------------------------------------------------- #\n",
    "        if name == 'bitcoinmagazine':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "            \n",
    "            \n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "                \n",
    "                # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                #article_response = requests.get(link)\n",
    "                #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                # Extraer el contenido de cada noticia.\n",
    "                #article_paragraphs = content.find_all('p')\n",
    "                #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                # Añadir los datos de la noticia a la lista.\n",
    "                news_data.append({\n",
    "                    'site': 'Bitcoin Magazine',\n",
    "                    'title': title,\n",
    "                    'pubDate': pub_date,\n",
    "                    'link': link,\n",
    "                    'description': description,\n",
    "                    'content': cleaned_content\n",
    "                })\n",
    "\n",
    "        # ----------------------------------------------------------------------- CryptoNews News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptonews':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto News',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "\n",
    "        # ----------------------------------------------------------------------- CryptoPotato News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptopotato':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto Potato',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "                    \n",
    "        # ----------------------------------------------------------------------- CryptoSlate News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptoslate':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto Slate',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "        \n",
    "        print(\"\\n--------------------------------------------------------------------------------------------------------\\n\")\n",
    "    else:\n",
    "        print(f'Failed to retrieve data from {name}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72240a83-485a-4b71-89d5-f1261f5ff9cf",
   "metadata": {},
   "source": [
    "Storing all the BTC news in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c63491-745a-4c38-820e-dd27d52639c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              site                                              title  \\\n",
      "0    CoinTelegraph   Bitcoin in ‘seasonal slog’ with slim chance o...   \n",
      "1    CoinTelegraph   Bitcoin traders celebrate ‘good news’ as BTC ...   \n",
      "2    CoinTelegraph   Bitcoin price shows strength above its recent...   \n",
      "3    CoinTelegraph   Bitcoin ETFs record combined $1.2B in outflow...   \n",
      "4    CoinTelegraph   Is crypto entering a bear market? — 5 Things ...   \n",
      "..             ...                                                ...   \n",
      "236  Crypto Potato  Substantial Net Outflows for Bitcoin, Ethereum...   \n",
      "237  Crypto Potato  These Alts Dumped the Most Weekly as Bitcoin (...   \n",
      "238  Crypto Potato  Is Bitcoin Gearing for a Major Move to $65,000...   \n",
      "239   Crypto Slate  The Privacy Imperative: Achieving true final s...   \n",
      "240    Crypto News  Bitcoin Price Forecast as ETF Inflows Signal I...   \n",
      "\n",
      "                             pubDate  \\\n",
      "0    Tue, 10 Sep 2024 03:16:56 +0100   \n",
      "1    Mon, 09 Sep 2024 21:53:03 +0100   \n",
      "2    Mon, 09 Sep 2024 20:07:16 +0100   \n",
      "3    Mon, 09 Sep 2024 09:28:35 +0100   \n",
      "4    Mon, 09 Sep 2024 08:14:00 +0100   \n",
      "..                               ...   \n",
      "236  Sun, 06 Oct 2024 11:27:50 +0000   \n",
      "237  Sun, 06 Oct 2024 08:25:29 +0000   \n",
      "238  Sun, 06 Oct 2024 06:12:06 +0000   \n",
      "239  Sun, 06 Oct 2024 19:30:28 +0000   \n",
      "240  Sun, 06 Oct 2024 08:50:53 +0000   \n",
      "\n",
      "                                                  link  \\\n",
      "0    https://cointelegraph.com/news/bitcoin-seasona...   \n",
      "1    https://cointelegraph.com/news/bitcoin-traders...   \n",
      "2    https://cointelegraph.com/news/bitcoin-price-s...   \n",
      "3    https://cointelegraph.com/news/bitcoin-etfs-1-...   \n",
      "4    https://cointelegraph.com/news/is-crypto-enter...   \n",
      "..                                                 ...   \n",
      "236  https://cryptopotato.com/substantial-net-outfl...   \n",
      "237  https://cryptopotato.com/these-alts-dumped-the...   \n",
      "238  https://cryptopotato.com/is-bitcoin-gearing-fo...   \n",
      "239  https://cryptoslate.com/the-privacy-imperative...   \n",
      "240  https://cryptonews.com/news/bitcoin-price-fore...   \n",
      "\n",
      "                                           description  \\\n",
      "0    “Potential upcoming near-term catalysts for Bi...   \n",
      "1    Bitcoin’s weekly close above a key support lev...   \n",
      "2    A stock market recovery, investors' anticipati...   \n",
      "3    Despite the outflows, crypto ETFs outshined th...   \n",
      "4    Bitcoin and crypto institutional product outfl...   \n",
      "..                                                 ...   \n",
      "236  October 1 was the worst day in terms of net ou...   \n",
      "237  XRP and DOGE are among the leaders in this adv...   \n",
      "238  Bitcoin’s price has recently experienced a dec...   \n",
      "239  The following is a guest post from Shane Neagl...   \n",
      "240  Bitcoin rebounds as ETF inflows hit $25.6 mill...   \n",
      "\n",
      "                                               content  \n",
      "0                                                  NaN  \n",
      "1                                                  NaN  \n",
      "2                                                  NaN  \n",
      "3                                                  NaN  \n",
      "4                                                  NaN  \n",
      "..                                                 ...  \n",
      "236  After being on a highly impressive streak of n...  \n",
      "237  Bitcoin’s price movements have calmed over the...  \n",
      "238  Bitcoin’s price has recently experienced a dec...  \n",
      "239  The following is a guest post from Shane Neagl...  \n",
      "240  \\nBitcoin is showing renewed strength, support...  \n",
      "\n",
      "[241 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertir la lista de diccionarios a un DataFrame de pandas.\n",
    "new_df = pd.DataFrame(news_data)\n",
    "\n",
    "# Concatenar el nuevo DataFrame con los datos existentes.\n",
    "final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados basados en el título.\n",
    "final_df.drop_duplicates(subset=['title'], inplace=True)\n",
    "\n",
    "# Guardar el DataFrame actualizado en el archivo CSV.\n",
    "final_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Mostrar las noticias acumuladas.\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99994d3-1059-43aa-af2b-cd8d0dd527bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
