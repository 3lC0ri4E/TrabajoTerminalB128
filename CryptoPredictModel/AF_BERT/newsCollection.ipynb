{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6389f926-9cc0-4cdc-a380-66187a6f8e34",
   "metadata": {},
   "source": [
    "TT. News Collection for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388ca728-54ee-4562-9328-1fe9baad6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías.\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb742b40-9edb-4f67-93bc-9128beb9c904",
   "metadata": {},
   "source": [
    "URLs of RSS sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac2fa80-feb0-4868-91ea-a7327cdb958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de páginas relacionadas con noticias de criptomonedas.\n",
    "\n",
    "# HTTP - 200 OK.\n",
    "\"\"\" RSS Feeds (XML). \"\"\"\n",
    "urls_dict = {\n",
    "    #'coindesk': 'https://www.coindesk.com/arc/outboundfeeds/rss',\n",
    "    'cointelegraph': 'https://cointelegraph.com/rss/tag/bitcoin',\n",
    "    'bitcoinmagazine': 'https://bitcoinmagazine.com/.rss/full/',\n",
    "    'cryptopotato': 'https://cryptopotato.com/feed/',\n",
    "    'cryptoslate': 'https://cryptoslate.com/feed/',\n",
    "    'cryptonews': 'https://cryptonews.com/news/feed/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d76b48-bcdd-4d43-8575-f97aed15c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo CSV para almacenar las noticias\n",
    "csv_file = 'news_data.csv'\n",
    "\n",
    "# Cargar datos previos si el archivo existe\n",
    "if os.path.exists(csv_file):\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "else:\n",
    "    existing_df = pd.DataFrame()  # Crear un DataFrame vacío si no existe el archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa7372-f2b5-48ab-891e-1a44d485157a",
   "metadata": {},
   "source": [
    "Getting soup and items for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e26d2f2-7f65-463d-baa5-4299ea073622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from cointelegraph:\n",
      "<Response [200]>\n",
      "Items from cointelegraph:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from bitcoinmagazine:\n",
      "<Response [200]>\n",
      "Items from bitcoinmagazine:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptopotato:\n",
      "<Response [403]>\n",
      "Failed to retrieve data from cryptopotato. Status code: 403\n",
      "Response from cryptoslate:\n",
      "<Response [200]>\n",
      "Items from cryptoslate:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptonews:\n",
      "<Response [200]>\n",
      "Items from cryptonews:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una lista para almacenar características de las noticias.\n",
    "news_data = []\n",
    "\n",
    "# Hacer solicitudes HTTP a las páginas web.\n",
    "for name, url in urls_dict.items():\n",
    "    response = requests.get(url)\n",
    "    print(f'Response from {name}:')\n",
    "    print(response)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parsear el contenido de las respuestas con BeautifulSoup.\n",
    "        soup = BeautifulSoup(response.content, 'xml')\n",
    "\n",
    "        # Extraer todos los elementos <item>.\n",
    "        items = soup.find_all('item')\n",
    "        print(f'Items from {name}:')\n",
    "        \n",
    "        # ----------------------------------------------------------------------- CoinDesk News. ----------------------------------------------------------------------- #\n",
    "        #\"\"\"\n",
    "        if name == 'coindesk':\n",
    "            # Iterar cada elemento <item> y extraer características de las noticias de CoinDesk\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo.\n",
    "                    article_response = requests.get(link)\n",
    "                    article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    article_paragraphs = article_soup.find_all('p')\n",
    "                    article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "                    \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'CoinDesk',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': article_content\n",
    "                    })\n",
    "            #\"\"\"\n",
    "        # ----------------------------------------------------------------------- CoinTelegraph News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cointelegraph':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia. \n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                #description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "            \n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "            \n",
    "                # Filtrar solo las noticias de Bitcoin\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                    \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = article_soup.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'CoinTelegraph',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description\n",
    "                        #'content': article_content\n",
    "                    })\n",
    "        \n",
    "        # ----------------------------------------------------------------------- BitcoinMagazine News. ----------------------------------------------------------------------- #\n",
    "        if name == 'bitcoinmagazine':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "            \n",
    "            \n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "                \n",
    "                # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                #article_response = requests.get(link)\n",
    "                #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                # Extraer el contenido de cada noticia.\n",
    "                #article_paragraphs = content.find_all('p')\n",
    "                #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                # Añadir los datos de la noticia a la lista.\n",
    "                news_data.append({\n",
    "                    'site': 'Bitcoin Magazine',\n",
    "                    'title': title,\n",
    "                    'pubDate': pub_date,\n",
    "                    'link': link,\n",
    "                    'description': description,\n",
    "                    'content': cleaned_content\n",
    "                })\n",
    "\n",
    "        # ----------------------------------------------------------------------- CryptoNews News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptonews':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto News',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "\n",
    "        # ----------------------------------------------------------------------- CryptoPotato News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptopotato':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto Potato',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "                    \n",
    "        # ----------------------------------------------------------------------- CryptoSlate News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptoslate':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                link = item.find('link').text\n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto Slate',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "        \n",
    "        print(\"\\n--------------------------------------------------------------------------------------------------------\\n\")\n",
    "    else:\n",
    "        print(f'Failed to retrieve data from {name}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72240a83-485a-4b71-89d5-f1261f5ff9cf",
   "metadata": {},
   "source": [
    "Storing all the BTC news in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c63491-745a-4c38-820e-dd27d52639c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                site                                              title  \\\n",
      "0      CoinTelegraph   Bitcoin in ‘seasonal slog’ with slim chance o...   \n",
      "1      CoinTelegraph   Bitcoin traders celebrate ‘good news’ as BTC ...   \n",
      "2      CoinTelegraph   Bitcoin price shows strength above its recent...   \n",
      "3      CoinTelegraph   Bitcoin ETFs record combined $1.2B in outflow...   \n",
      "4      CoinTelegraph   Is crypto entering a bear market? — 5 Things ...   \n",
      "..               ...                                                ...   \n",
      "894  Bitcoinmagazine  Newmarket Capital Launches Battery Finance, Bi...   \n",
      "895  Bitcoinmagazine  The Chart That Shows Bitcoin’s Bull Run Won’t ...   \n",
      "896  Bitcoinmagazine                    JIPPI IS POKÉMON GO FOR BITCOIN   \n",
      "897  Bitcoinmagazine    Why $100,000 Bitcoin Is Right Around The Corner   \n",
      "898       Cryptonews  XRP Jumps 8% as Bitcoin Recovers to $96K Amid ...   \n",
      "\n",
      "                             pubDate  \\\n",
      "0    Tue, 10 Sep 2024 03:16:56 +0100   \n",
      "1    Mon, 09 Sep 2024 21:53:03 +0100   \n",
      "2    Mon, 09 Sep 2024 20:07:16 +0100   \n",
      "3    Mon, 09 Sep 2024 09:28:35 +0100   \n",
      "4    Mon, 09 Sep 2024 08:14:00 +0100   \n",
      "..                               ...   \n",
      "894    Mon, 25 Nov 2024 14:15:42 GMT   \n",
      "895    Thu, 21 Nov 2024 15:26:49 GMT   \n",
      "896    Wed, 20 Nov 2024 18:12:38 GMT   \n",
      "897    Mon, 18 Nov 2024 23:21:33 GMT   \n",
      "898  Fri, 29 Nov 2024 07:34:24 +0000   \n",
      "\n",
      "                                                  link  \\\n",
      "0    https://cointelegraph.com/news/bitcoin-seasona...   \n",
      "1    https://cointelegraph.com/news/bitcoin-traders...   \n",
      "2    https://cointelegraph.com/news/bitcoin-price-s...   \n",
      "3    https://cointelegraph.com/news/bitcoin-etfs-1-...   \n",
      "4    https://cointelegraph.com/news/is-crypto-enter...   \n",
      "..                                                 ...   \n",
      "894  https://bitcoinmagazine.com/business/newmarket...   \n",
      "895  https://bitcoinmagazine.com/markets/chart-bitc...   \n",
      "896  https://bitcoinmagazine.com/culture/jippi-is-p...   \n",
      "897  https://bitcoinmagazine.com/takes/why-100000-b...   \n",
      "898  https://cryptonews.com/news/xrp-jumps-8-amid-b...   \n",
      "\n",
      "                                           description  \\\n",
      "0    “Potential upcoming near-term catalysts for Bi...   \n",
      "1    Bitcoin’s weekly close above a key support lev...   \n",
      "2    A stock market recovery, investors' anticipati...   \n",
      "3    Despite the outflows, crypto ETFs outshined th...   \n",
      "4    Bitcoin and crypto institutional product outfl...   \n",
      "..                                                 ...   \n",
      "894  Battery Finance enables borrowers to use bitco...   \n",
      "895  Sure, there might be sell-offs, but we're far ...   \n",
      "896  Gamified Bitcoin education will serve as the c...   \n",
      "897  Today's tidal wave of bullish Bitcoin developm...   \n",
      "898  <p>XRP token soared more than 8% in the last 2...   \n",
      "\n",
      "                                               content  \n",
      "0                                                       \n",
      "1                                                       \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "..                                                 ...  \n",
      "894  Battery Finance enables borrowers to use bitco...  \n",
      "895  Sure, there might be sell-offs, but we're far ...  \n",
      "896  Gamified Bitcoin education will serve as the c...  \n",
      "897  Today's tidal wave of bullish Bitcoin developm...  \n",
      "898  <p>XRP token soared more than 8% in the last 2...  \n",
      "\n",
      "[899 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertir la lista de diccionarios a un DataFrame de pandas.\n",
    "new_df = pd.DataFrame(news_data)\n",
    "\n",
    "# Concatenar el nuevo DataFrame con los datos existentes.\n",
    "final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados basados en el título.\n",
    "final_df.drop_duplicates(subset=['title'], inplace=True)\n",
    "\n",
    "# Limpieza de valores NaN en columna 'content'.\n",
    "final_df['content'] = final_df['content'].fillna('')\n",
    "\n",
    "# Limpieza del caracter salto de línea '\\n' en la columna 'content'.\n",
    "final_df['content'] = final_df['content'].str.replace('\\n', ' ')\n",
    "\n",
    "# Guardar el DataFrame actualizado en el archivo CSV.\n",
    "final_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Mostrar las noticias acumuladas.\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ed059-955a-44c0-93e7-063555924979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
