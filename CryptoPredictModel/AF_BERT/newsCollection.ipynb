{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6389f926-9cc0-4cdc-a380-66187a6f8e34",
   "metadata": {},
   "source": [
    "TT. News Collection for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388ca728-54ee-4562-9328-1fe9baad6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías.\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb742b40-9edb-4f67-93bc-9128beb9c904",
   "metadata": {},
   "source": [
    "URLs of RSS sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac2fa80-feb0-4868-91ea-a7327cdb958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de páginas relacionadas con noticias de criptomonedas.\n",
    "\n",
    "# HTTP - 200 OK.\n",
    "\"\"\" RSS Feeds (XML). \"\"\"\n",
    "urls_dict = {\n",
    "    #'coindesk': 'https://www.coindesk.com/arc/outboundfeeds/rss',\n",
    "    'cointelegraph': 'https://cointelegraph.com/rss/tag/bitcoin',\n",
    "    'bitcoinmagazine': 'https://bitcoinmagazine.com/.rss/full/',\n",
    "    'cryptopotato': 'https://cryptopotato.com/feed/',\n",
    "    'cryptoslate': 'https://cryptoslate.com/feed/',\n",
    "    'cryptonews': 'https://cryptonews.com/news/feed/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d76b48-bcdd-4d43-8575-f97aed15c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo CSV para almacenar las noticias\n",
    "csv_file = 'news_data.csv'\n",
    "\n",
    "# Cargar datos previos si el archivo existe\n",
    "if os.path.exists(csv_file):\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "else:\n",
    "    existing_df = pd.DataFrame()  # Crear un DataFrame vacío si no existe el archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa7372-f2b5-48ab-891e-1a44d485157a",
   "metadata": {},
   "source": [
    "Getting soup and items for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e26d2f2-7f65-463d-baa5-4299ea073622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from cointelegraph:\n",
      "<Response [200]>\n",
      "Items from cointelegraph:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from bitcoinmagazine:\n",
      "<Response [200]>\n",
      "Items from bitcoinmagazine:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptopotato:\n",
      "<Response [403]>\n",
      "Failed to retrieve data from cryptopotato. Status code: 403\n",
      "Response from cryptoslate:\n",
      "<Response [200]>\n",
      "Items from cryptoslate:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Response from cryptonews:\n",
      "<Response [200]>\n",
      "Items from cryptonews:\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una lista para almacenar características de las noticias.\n",
    "news_data = []\n",
    "\n",
    "# Hacer solicitudes HTTP a las páginas web.\n",
    "for name, url in urls_dict.items():\n",
    "    response = requests.get(url)\n",
    "    print(f'Response from {name}:')\n",
    "    print(response)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parsear el contenido de las respuestas con BeautifulSoup.\n",
    "        soup = BeautifulSoup(response.content, 'xml')\n",
    "\n",
    "        # Extraer todos los elementos <item>.\n",
    "        items = soup.find_all('item')\n",
    "        print(f'Items from {name}:')\n",
    "        \n",
    "        # ----------------------------------------------------------------------- CoinDesk News. ----------------------------------------------------------------------- #\n",
    "        #\"\"\"\n",
    "        if name == 'coindesk':\n",
    "            # Iterar cada elemento <item> y extraer características de las noticias de CoinDesk\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                # Convertir pubDate a formato \"EEE, dd, MMM, yyyy\"\n",
    "                pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%a, %d %b %Y')\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo.\n",
    "                    article_response = requests.get(link)\n",
    "                    article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    article_paragraphs = article_soup.find_all('p')\n",
    "                    article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "                    \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'CoinDesk',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': article_content\n",
    "                    })\n",
    "            #\"\"\"\n",
    "        # ----------------------------------------------------------------------- CoinTelegraph News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cointelegraph':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia. \n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                # Convertir pubDate a formato \"EEE, dd, MMM, yyyy\"\n",
    "                pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%a, %d %b %Y')\n",
    "                link = item.find('link').text\n",
    "                #description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "            \n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "            \n",
    "                # Filtrar solo las noticias de Bitcoin\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                    \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = article_soup.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'CoinTelegraph',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description\n",
    "                        #'content': article_content\n",
    "                    })\n",
    "        \n",
    "        # ----------------------------------------------------------------------- BitcoinMagazine News. ----------------------------------------------------------------------- #\n",
    "        if name == 'bitcoinmagazine':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "\n",
    "                # Eliminar el sufijo 'GMT' y convertir la fecha al formato deseado\n",
    "                pub_date_cleaned = pub_date.replace(' GMT', '')  # Eliminar ' GMT'\n",
    "                pub_date_parsed = datetime.strptime(pub_date_cleaned, '%a, %d %b %Y %H:%M:%S') \n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "            \n",
    "            \n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "                \n",
    "                # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                #article_response = requests.get(link)\n",
    "                #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                # Extraer el contenido de cada noticia.\n",
    "                #article_paragraphs = content.find_all('p')\n",
    "                #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                # Añadir los datos de la noticia a la lista.\n",
    "                news_data.append({\n",
    "                    'site': 'Bitcoin Magazine',\n",
    "                    'title': title,\n",
    "                    'pubDate': pub_date,\n",
    "                    'link': link,\n",
    "                    'description': description,\n",
    "                    'content': cleaned_content\n",
    "                })\n",
    "\n",
    "        # ----------------------------------------------------------------------- CryptoNews News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptonews':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                # Convertir pubDate a formato \"EEE, dd, MMM, yyyy\"\n",
    "                pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%a, %d %b %Y')\n",
    "                link = item.find('link').text\n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto News',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "\n",
    "        # ----------------------------------------------------------------------- CryptoPotato News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptopotato':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                # Convertir pubDate a formato \"EEE, dd, MMM, yyyy\"\n",
    "                pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%a, %d %b %Y')\n",
    "                link = item.find('link').text\n",
    "                description = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto Potato',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "                    \n",
    "        # ----------------------------------------------------------------------- CryptoSlate News. ----------------------------------------------------------------------- #\n",
    "        if name == 'cryptoslate':\n",
    "        # Iterar cada elemento <item> y las características de cada noticia.\n",
    "            for item in items:\n",
    "                title = item.find('title').text\n",
    "                pub_date = item.find('pubDate').text\n",
    "                # Convertir pubDate a formato \"EEE, dd, MMM, yyyy\"\n",
    "                pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%a, %d %b %Y')\n",
    "                link = item.find('link').text\n",
    "                description_html = item.find('description').text if item.find('description') else 'No description available'\n",
    "                content = item.find('content:encoded').text if item.find('content:encoded') else 'No description available'\n",
    "                #news_data.append({'title': title, 'pubDate': pub_date, 'link': link, 'description': description})\n",
    "                cleaned_content = BeautifulSoup(content, 'html.parser').get_text()\n",
    "            \n",
    "                # Parsear el contenido HTML de la descripción y extraer solo el texto.\n",
    "                description_soup = BeautifulSoup(description_html, 'html.parser')\n",
    "                description = description_soup.get_text(strip=True)\n",
    "                \n",
    "                # Filtrar solo las noticias de Bitcoin.\n",
    "                if 'bitcoin' in title.lower() or 'BTC' in title.lower():\n",
    "                    # Hacer una solicitud HTTP a la URL de la noticia para obtener el contenido completo de la noticia en cuestión.\n",
    "                    #article_response = requests.get(link)\n",
    "                    #article_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "                \n",
    "                    # Extraer el contenido de cada noticia.\n",
    "                    #article_paragraphs = content.find_all('p')\n",
    "                    #article_content = ' '.join([paragraph.text for paragraph in article_paragraphs])\n",
    "            \n",
    "                    # Añadir los datos de la noticia a la lista.\n",
    "                    news_data.append({\n",
    "                        'site': 'Crypto Slate',\n",
    "                        'title': title,\n",
    "                        'pubDate': pub_date,\n",
    "                        'link': link,\n",
    "                        'description': description,\n",
    "                        'content': cleaned_content\n",
    "                    })\n",
    "        \n",
    "        print(\"\\n--------------------------------------------------------------------------------------------------------\\n\")\n",
    "    else:\n",
    "        print(f'Failed to retrieve data from {name}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72240a83-485a-4b71-89d5-f1261f5ff9cf",
   "metadata": {},
   "source": [
    "Storing all the BTC news in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c63491-745a-4c38-820e-dd27d52639c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               site                                              title  \\\n",
      "0     CoinTelegraph   Bitcoin in ‘seasonal slog’ with slim chance o...   \n",
      "1     CoinTelegraph   Bitcoin traders celebrate ‘good news’ as BTC ...   \n",
      "2     CoinTelegraph   Bitcoin price shows strength above its recent...   \n",
      "3     CoinTelegraph   Bitcoin ETFs record combined $1.2B in outflow...   \n",
      "4     CoinTelegraph   Is crypto entering a bear market? — 5 Things ...   \n",
      "...             ...                                                ...   \n",
      "1058   Crypto Slate  MicroStrategy now controls over 2% of Bitcoin ...   \n",
      "1059    Crypto News  Riot Plans $500M Convertible Notes Offering to...   \n",
      "1060    Crypto News  Bitcoin’s Rally Could Hit Pause in 2025, Says ...   \n",
      "1061    Crypto News  El Salvador to Adjust Bitcoin Policy for $1.3 ...   \n",
      "1062    Crypto News  Schiff Brands Bitcoin ‘Public Enemy #1’ Amid B...   \n",
      "\n",
      "               pubDate                                               link  \\\n",
      "0     Tue, 10 Sep 2024  https://cointelegraph.com/news/bitcoin-seasona...   \n",
      "1     Mon, 09 Sep 2024  https://cointelegraph.com/news/bitcoin-traders...   \n",
      "2     Mon, 09 Sep 2024  https://cointelegraph.com/news/bitcoin-price-s...   \n",
      "3     Mon, 09 Sep 2024  https://cointelegraph.com/news/bitcoin-etfs-1-...   \n",
      "4     Mon, 09 Sep 2024  https://cointelegraph.com/news/is-crypto-enter...   \n",
      "...                ...                                                ...   \n",
      "1058  Mon, 09 Dec 2024  https://cryptoslate.com/insights/microstrategy...   \n",
      "1059  Mon, 09 Dec 2024  https://cryptonews.com/news/riot-plans-500m-co...   \n",
      "1060  Mon, 09 Dec 2024  https://cryptonews.com/news/bitcoins-rally-cou...   \n",
      "1061  Mon, 09 Dec 2024  https://cryptonews.com/news/el-salvador-to-adj...   \n",
      "1062  Mon, 09 Dec 2024  https://cryptonews.com/news/schiff-brands-bitc...   \n",
      "\n",
      "                                            description  \\\n",
      "0     “Potential upcoming near-term catalysts for Bi...   \n",
      "1     Bitcoin’s weekly close above a key support lev...   \n",
      "2     A stock market recovery, investors' anticipati...   \n",
      "3     Despite the outflows, crypto ETFs outshined th...   \n",
      "4     Bitcoin and crypto institutional product outfl...   \n",
      "...                                                 ...   \n",
      "1058  MicroStrategy significantly expanded its Bitco...   \n",
      "1059  Riot Platforms plans to raise $500 million thr...   \n",
      "1060  Bitcoin’s price movements, meanwhile, exhibit ...   \n",
      "1061  El Salvador will reportedly make Bitcoin accep...   \n",
      "1062  Peter Schiff, a vocal gold supporter, intensif...   \n",
      "\n",
      "                                                content  \n",
      "0                                                        \n",
      "1                                                        \n",
      "2                                                        \n",
      "3                                                        \n",
      "4                                                        \n",
      "...                                                 ...  \n",
      "1058  MicroStrategy significantly expanded its Bitco...  \n",
      "1059   Bitcoin infrastructure firm Riot Platforms ha...  \n",
      "1060   Once considered an unrealistic milestone, Bit...  \n",
      "1061   El Salvador is reportedly revising its crypto...  \n",
      "1062   Peter Schiff, a prominent gold advocate, has ...  \n",
      "\n",
      "[1002 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertir la lista de diccionarios a un DataFrame de pandas.\n",
    "new_df = pd.DataFrame(news_data)\n",
    "\n",
    "# Concatenar el nuevo DataFrame con los datos existentes.\n",
    "final_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados basados en el título.\n",
    "final_df.drop_duplicates(subset=['title'], inplace=True)\n",
    "\n",
    "# Limpieza de valores NaN en columna 'content'.\n",
    "final_df['content'] = final_df['content'].fillna('')\n",
    "\n",
    "# Limpieza del caracter salto de línea '\\n' en la columna 'content'.\n",
    "final_df['content'] = final_df['content'].str.replace('\\n', ' ')\n",
    "\n",
    "# Guardar el DataFrame actualizado en el archivo CSV.\n",
    "final_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Mostrar las noticias acumuladas.\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ed059-955a-44c0-93e7-063555924979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
